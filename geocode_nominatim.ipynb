{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ec2b13-0163-4ea1-81c7-682ef2f25387",
   "metadata": {},
   "source": [
    "# Address Geocoding Notebook\n",
    "This notebook provides a detailed workflow for geocoding addresses from tabular data such as CSV files. It covers data import, address data cleaning, resolving unmatched addresses, visualizing results on a map, QC operations, and exporting results to GIS format. Nominatim and Google Maps API are the primary geocoders used however other ones may be used from the geopy.geocoders library. Please note you must have your own Google Maps API key to use that service. Nominatim does not require an API key. This notebook is based upon https://youtu.be/N6itC6hbOvo?si=gY-hNBpRieMCEYqu youtube video but modified with additional features and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1e58e-1a7d-4a2b-b7fb-d14c8ae6b340",
   "metadata": {},
   "source": [
    "## 1. Import Packages and Libraries\n",
    "These libraries may be installed into your Python virtual environment using pip: pandas, geopandas, leafmap, geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f4986-b1be-41d1-a82e-ef00872f1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import leafmap.foliumap as leafmap\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import GoogleV3\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039735d-f35d-4035-b3c2-3d3fea618b1d",
   "metadata": {},
   "source": [
    "## 2. Create Data Folders\n",
    "Unless a path is specified, these folders get created in the same location by default where your notebook Python file is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae1477-89ad-4b05-a83b-d7d503ffc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data' # where input data such as csv files are placed\n",
    "output_folder = 'output'\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3db54c-cca3-4b48-bdae-8e6ef465f24e",
   "metadata": {},
   "source": [
    "## 3. Create Address Dataframe\n",
    "Specify the name of a CSV file located in the data folder created from above. This file will then be imported into a new Pandas dataframe named address_df. Alternatively, a database connection may be created here to create the dataframe from a database table. This cell will output basic information about the new dataframe and the tabular view of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea08214-2727-4f1d-8bd0-84dc613cdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'Dialer_Export_1716925317652.csv'  # name of csv file\n",
    "csv_file_path = os.path.join(data_folder, csv_file)\n",
    "address_df = pd.read_csv(csv_file_path)\n",
    "address_df.info()\n",
    "address_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16dd04e-11cf-4017-93eb-ffc1ae5e483e",
   "metadata": {},
   "source": [
    "## 4. Display Column Percent Complete\n",
    "This cell will display the % complete and datatype for each column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343327d-5dc1-4568-b047-c226ae1c0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness = (1 - address_df.isna().mean()) * 100\n",
    "data_types = address_df.dtypes\n",
    "column_info = pd.DataFrame({\n",
    "    'Completeness (%)': completeness,\n",
    "    'Data Type': data_types\n",
    "})\n",
    "column_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df34659-d42b-4503-b5aa-1f584b0d47ee",
   "metadata": {},
   "source": [
    "## 5. Clean Address Data\n",
    "Clean address columns if necessary. The below sample code provides techniques which may be used to clean address data if required. Additional code may be added as needed. This code and its use is explained in more detail in the youtube video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027480cb-5fe8-44c6-9be0-02572b4659d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def make_ordinal(match):\n",
    "    #n = int(match.group(1))\n",
    "    #if 11 <= (n % 100) <= 13:\n",
    "        #suffix = 'th'\n",
    "    #else:\n",
    "        #suffix = ['th', 'st', 'nd', 'rd', 'th'][min(n % 10, 4)]\n",
    "    #return str(n) + suffix + match.group(2)\n",
    "    \n",
    "#def update_address(row):\n",
    "    #old_address = row['Address']\n",
    "    #pattern = r'(\\d+)(\\s+(?:Street|Avenue|Blvd|Drive))'\n",
    "    #result = re.sub(pattern, make_ordinal, old_address)\n",
    "\n",
    "#address_df['address_fixed'] = address_df.apply(update_address, axis=1)\n",
    "\n",
    "#address_df = address_df.head(250) # just to shorten the dataset for testing / dev\n",
    "\n",
    "# Check for duplicate addresses if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758c54b-fed3-41d9-8503-ce911095279c",
   "metadata": {},
   "source": [
    "## 6. Create Full Address Column\n",
    "Address columns are concatenated together to create a full_address column. If addresses are already in a single column, this operation will not be needed. Trailing whitespace is removed and the column is displayed. Use openstreetmap.org (which powers Nominatim) to manually geocode a few addresses from the full_address column for test. If geocoding fails, additional cleaning may be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9544f2f-1cbc-4800-a2b4-331caaf4cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df['full_address'] = (\n",
    "    address_df['Address'] + ',' + \n",
    "    address_df['City'] + ',' +\n",
    "    address_df['State'] + ',' + \n",
    "    address_df['Zip'].astype(str)\n",
    ")\n",
    "# Removing any leading and trailing whitespace\n",
    "address_df['full_address'] = address_df['full_address'].str.strip()\n",
    "address_df['full_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e79219-1889-4b39-9433-247cb9ca9e18",
   "metadata": {},
   "source": [
    "## 7. Geocode Using Nominatim\n",
    "Geocode address_df dataframe using Nominatim. This process creates a new column in the dataframe named location which stores a location object if the address successfully geocodes. If the address fails to geocode, a None value will be stored in the location column. The geocoder may be tested on single addresses prior to running the whole dataframe if needed (see the commented code and make sure to uncomment the last line which geocodes the whole dataframe). A progress bar will appear below the cell to indicate geocoding progress. The Nominatim API only allows 1 request per and is therefore very slow for large datasets. For faster performance, use a local installation of Nominatim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34000e58-8913-43b2-b097-f33c08113ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "locator = Nominatim(user_agent='justinhawley', timeout=10)\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1) # set rate limiter as Nominatim can only receive 1 request per second\n",
    "\n",
    "# Test the geocoder\n",
    "#geocode('1422 N 35TH ST ,MILWAUKEE,Wisconsin,53208')\n",
    "\n",
    "address_df['location'] = address_df['full_address'].progress_apply(geocode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbbe4be-7c7f-495b-8f9d-d76e76f95c54",
   "metadata": {},
   "source": [
    "## 8. Check Unmatched Records (Nominatim)\n",
    "Check for any null location objects for addresses that failed to geocode. Percentage unmatched is reported and a new dataframe is created for any unmatched records. The unmatched records are then removed from the address_df dataframe so it only contains matched records. The total matched and unmatched record counts should equal the original dataset total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967e5c8-152a-4a06-94ff-28d4758746dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominatim_unmatched_df = address_df[address_df['location'].isna()] # create new dataframe for unmatched\n",
    "nominatim_unmatched_percent = (len(nominatim_unmatched_df) / len(address_df)) * 100.0\n",
    "print(f'{len(nominatim_unmatched_df)} ({nominatim_unmatched_percent}%) unmatched records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b390f95-2565-45d1-bb0c-97a3bece367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new matched only datafram (nominatim_matched_df) from address_df\n",
    "if len(nominatim_unmatched_df) > 0:\n",
    "    nominatim_matched_df = address_df[-address_df['location'].isna()] # create matched dataframe\n",
    "else:\n",
    "    nominatim_matched_df = address_df\n",
    "\n",
    "# Verify unmatched records removed from address_df\n",
    "print(len(nominatim_unmatched_df), 'unmatched records.', len(nominatim_matched_df), 'matched records', 'for a total of:',len(nominatim_matched_df) + len(nominatim_unmatched_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e283237-ae33-4753-a7ea-a9aa81846568",
   "metadata": {},
   "source": [
    "## 9. Geocode unmatched records with Google Maps API\n",
    "The remaining unmatched records may be geocoded with Google Maps API or any other geocoding service. You must have your own API key to use Google Maps API. Matched records are placed into a new dataframe named address_df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2015c-ec80-463d-bd06-b13db736eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'YOUR GOOGLE MAPS API KEY' \n",
    "locator = GoogleV3(api_key=api_key, timeout=10)\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1) # may change to 5\n",
    "\n",
    "# test the geocoder\n",
    "# geocode('1422 N 35TH ST ,MILWAUKEE,Wisconsin,53208')\n",
    "tqdm.pandas()  # Adds progress bar for apply\n",
    "\n",
    "#attempt to geocode unmatched dataframe\n",
    "nominatim_unmatched_df['location'] = nominatim_unmatched_df['full_address'].progress_apply(geocode) #original line\n",
    "google_matched_df = nominatim_unmatched_df # create new dataframe for readibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffe370-5445-47a9-8647-9b6bd34ad49c",
   "metadata": {},
   "source": [
    "## 10. Check Unmatched Again\n",
    "Check for unmatched records again after the Google Maps API geocode. Remaining unmatched records are placed in google_unmatched_df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99fcc43-b099-4559-93f3-23ae23890c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query google_matched_df (from above geocode) to see if there are still more unmatched\n",
    "google_unmatched_df = google_matched_df[google_matched_df['location'].isna()]\n",
    "google_unmatched_percent = (len(google_unmatched_df) / len(google_matched_df)) * 100.0\n",
    "print(f'{len(google_unmatched_df)} ({google_unmatched_percent}%) unmatched records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a9b28-a97d-45f8-8cd5-e97784f9ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Unmatched records, remove from google_matched_df\n",
    "if len(google_unmatched_df) > 0:\n",
    "    google_matched_df = google_matched_df[-google_matched_df['location'].isna()]\n",
    "\n",
    "# Verify unmatched records removed from google_matched_df. Dataframe will be empty if there was no matches from Google API geocode\n",
    "len(google_matched_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c56e5-e025-4df3-8bc1-bca5ff39fd8c",
   "metadata": {},
   "source": [
    "## 11. Add Lat Long Columns Verify Matched and Unmatched Dataframe Counts\n",
    "Verify the dataframe record counts for Nominatim and Google API geocoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91676556-7cf8-4464-a0ed-3b658aba9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lat long columns\n",
    "google_matched_df['latitude'] = google_matched_df['location'].apply(lambda loc: loc.latitude if loc else None)\n",
    "google_matched_df['longitude'] = google_matched_df['location'].apply(lambda loc: loc.longitude if loc else None)\n",
    "\n",
    "google_unmatched_df['latitude'] = google_unmatched_df['location'].apply(lambda loc: loc.latitude if loc else None)\n",
    "google_unmatched_df['longitude'] = google_unmatched_df['location'].apply(lambda loc: loc.longitude if loc else None)\n",
    "\n",
    "nominatim_matched_df['latitude'] = nominatim_matched_df['location'].apply(lambda loc: loc.latitude if loc else None)\n",
    "nominatim_matched_df['longitude'] = nominatim_matched_df['location'].apply(lambda loc: loc.longitude if loc else None)\n",
    "\n",
    "nominatim_unmatched_df['latitude'] = nominatim_unmatched_df['location'].apply(lambda loc: loc.latitude if loc else None)\n",
    "nominatim_unmatched_df['longitude'] = nominatim_unmatched_df['location'].apply(lambda loc: loc.longitude if loc else None)\n",
    "# Google unmatched is the final unmatched count\n",
    "print(f'Nominatim matched: {len(nominatim_matched_df)} \\nNominatim unmatched: {len(nominatim_unmatched_df)}\\nGoogle matched: {len(google_matched_df)}\\nGoogle unmatched: {len(google_unmatched_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea2d82-fcb2-4a0e-a02d-6a1ec6d18fd0",
   "metadata": {},
   "source": [
    "## 12. Manually Correct Remaining Unmatched Records\n",
    "If possible, manually add latitude and longitude values for any remaining unmatched records in unmatched2_df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e22da0-3767-4439-b6b3-e922298469d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_unmatched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f8062-929e-4616-b1d9-997bb42ce6ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manually assign lat long values to each unmatched record\n",
    "# Make sure to use correct index from above\n",
    "google_unmatched_df.loc[5994,['latitude', 'longitude']] = (46.015715937394, -91.48644435376464) #updates row 5994 from above unmatched\n",
    "\n",
    "# Add updated record to google_matched_df and remove it from google_unmatched_df \n",
    "updated_record = google_unmatched_df.loc[5994]\n",
    "updated_record = updated_record.to_frame().T\n",
    "google_unmatched_df = google_unmatched_df.drop(5994)\n",
    "google_matched_df = pd.concat([google_matched_df, updated_record], ignore_index=True, axis=0)\n",
    "\n",
    "# Verify final dataframe counts\n",
    "print(f'Nominatim matched: {len(nominatim_matched_df)} \\nNominatim unmatched: {len(nominatim_unmatched_df)}\\nGoogle matched: {len(google_matched_df)}\\nGoogle unmatched: {len(google_unmatched_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc7f6e-01b8-46a5-9804-f13d416f0571",
   "metadata": {},
   "source": [
    "## 12. Combined Matched Dataframes\n",
    "Combine matched matched records into a new single dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5cd854-4afb-415a-9026-0c1f75c6d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_final_df = pd.concat([nominatim_matched_df, google_matched_df], axis=0)\n",
    "matched_final_df = matched_final_df.reset_index(drop=True)\n",
    "\n",
    "unmatched_final_df = google_unmatched_df # google_unmatched_df is the final unmatched. It is renamed to unmatched_final for readability\n",
    "\n",
    "#len(matched_final)\n",
    "matched_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494361a7-2458-44e7-b25a-916dfab93a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify address_df_merged has no null lat long values\n",
    "matched_final_df[matched_final_df['latitude'].isna() | matched_final_df['longitude'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f874af-c2d2-4766-b68a-e6915b125cfd",
   "metadata": {},
   "source": [
    "## 14. Create Geometry and Geodataframe\n",
    "Create a geometry column and a geodataframe for the final unmatched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8502eb-606a-4a69-b5e3-6b5047a3a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = gpd.points_from_xy(matched_final_df.longitude, matched_final_df.latitude)\n",
    "matched_final_gdf = gpd.GeoDataFrame(matched_final_df, crs='EPSG:4326', geometry = geometry)\n",
    "matched_final_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d79551-1af6-40c8-bc55-2a02c9904d91",
   "metadata": {},
   "source": [
    "## 15. Create Geometry and Geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd8543f-41f4-43e1-a31c-7656c67b5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the location column as it throws an error when displaying the below map (TypeError: Object of type Location is not JSON serializable)\n",
    "del matched_final_gdf['location']\n",
    "\n",
    "# Correct any int64 columns which throws the same error\n",
    "def make_json_serializable(val):\n",
    "    if isinstance(val, (pd.Int64Dtype, pd.Float64Dtype)):\n",
    "        return val.item()\n",
    "    return val\n",
    "\n",
    "matched_final_gdf = matched_final_gdf.applymap(make_json_serializable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caccb79-d8a6-4a48-8831-df10c7441433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "m = leafmap.Map(width=800, height=500)\n",
    "matched_final_gdf.explore(m=m)\n",
    "m.zoom_to_gdf(matched_final_gdf)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f40f07-98de-4727-b24b-3e4733a80cf4",
   "metadata": {},
   "source": [
    "## 16. QC Final Matched\n",
    "More QC operations may be added here. Currently this code checks for groups of coincident points and reports of they have the same or different addresses. Additionally it might be valuable to have the option of removing duplicate addresses prior to geocoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4868b6a-b77c-4974-9f4c-82788d39ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coincident_points = matched_final_gdf[matched_final_gdf.duplicated(subset='geometry', keep=False)]\n",
    "\n",
    "# Step 2: Group by geometries\n",
    "groups = coincident_points.groupby(coincident_points.geometry.apply(lambda geom: geom.wkt))\n",
    "\n",
    "# Step 3: Check for same or different addresses in each group\n",
    "found_different_addresses = False\n",
    "for geom_wkt, group in groups:\n",
    "    unique_addresses = group['full_address'].unique()\n",
    "    if len(unique_addresses) == 1:\n",
    "        print(f\"All {len(group)} points at {geom_wkt} have the same address: {unique_addresses[0]}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Points at {geom_wkt} have different addresses: {unique_addresses}. Count: {len(group)}\")\n",
    "        print()\n",
    "        found_different_addresses = True\n",
    "\n",
    "if not found_different_addresses:\n",
    "    print(\"No groups with different addresses found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267e413-e145-459a-86bd-6d44aa84754b",
   "metadata": {},
   "source": [
    "## 17. Export Matched and Unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6bc950-6428-4152-8e0e-dce7c008136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export matched to shapefile\n",
    "output_file = csv_file.replace('.csv', '_geocode.shp')\n",
    "output_path = os.path.join(output_folder, output_file)\n",
    "matched_final_gdf .to_file(filename=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd6245-c7ab-4610-af62-f70d8f46d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export unmatched to csv file\n",
    "output_file = csv_file.replace('.csv', '_unmatched.csv')\n",
    "output_path = os.path.join(output_folder, output_file)\n",
    "unmatched_final_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b1e35-1745-41ec-80b0-02bf9a632e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
